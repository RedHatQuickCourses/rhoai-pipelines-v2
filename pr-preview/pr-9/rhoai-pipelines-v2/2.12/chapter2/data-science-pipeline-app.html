<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Data Science Pipeline Applications :: RHOAI Data Science Pipelines</title>
    <link rel="prev" href="managing-dsp-pipelines.html">
    <link rel="next" href="rhoai-resources.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">RHOAI Data Science Pipelines</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="rhoai-pipelines-v2" data-version="2.12">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">RHOAI Data Science Pipelines</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../LABENV/index.html">Lab Environment</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/minio-install.html">MinIO S3 Compatible Storage Setup</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter1/dsp-intro.html">Introduction to ML Pipelines</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter1/dsp-concepts.html">Data Science Pipeline Concepts</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">Data Science Pipelines</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="managing-dsp-pipelines.html">RHOAI Pipeline Overview</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="data-science-pipeline-app.html">Data Science Pipeline Applications</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rhoai-resources.html">OpenShift AI Resources</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter3/index.html">Creating Pipelines with Elyra</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter3/elyra-pipelines.html">Elyra Pipelines</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter4/index.html">KFP SDK</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter4/kfp-import.html">Kubeflow Pipelines SDK</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter4/section1.html">blah blah blah 2</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../appendix/appendix.html">Appendix A</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">RHOAI Data Science Pipelines</span>
    <span class="version">2.12</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">RHOAI Data Science Pipelines</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">2.12</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">RHOAI Data Science Pipelines</a></li>
    <li><a href="index.html">Data Science Pipelines</a></li>
    <li><a href="data-science-pipeline-app.html">Data Science Pipeline Applications</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Data Science Pipeline Applications</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>The <strong>DataSciencePipelineApplication</strong> (dspa) custom resource creates several pods that are necessary to utilize the tools.  This includes the creation of an API endpoint and a database where metadata is stored.  The API endpoint is used by the OpenShift AI Dashboard, as well as tools like <strong>Elyra</strong> and the <strong>kfp</strong> package to manage and execute pipelines.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/dpsa_services.gif" alt="dpsa services" width="600">
</div>
</div>
<div class="paragraph">
<p>In Red Hat OpenShift AI, the Data Science Pipeline runtime consists of the following components:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A Data Science Pipeline Server container.</p>
</li>
<li>
<p>A MariaDB database for storing pipeline definitions and results.</p>
</li>
<li>
<p>A Pipeline scheduler for scheduling pipeline runs.</p>
</li>
<li>
<p>Metadata envoy and grpc pods</p>
</li>
<li>
<p>A workflow controller for dspa</p>
</li>
<li>
<p>A Persistent Agent to record the set of containers that are executed as well as their inputs and outputs.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Additionally, the <strong>DataSciencePipelineApplication</strong> requires an S3 compatible storage solution to store artifacts that are generated in the pipeline.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Any S3 compatible storage solution can be used for Data Science Pipelines, including AWS S3, OpenShift Data Foundation, or Minio. In this course we will use Minio as it is a lightweight and easy to deploy S3 storage solution. Red Hat recommends OpenShift Data Foundation in scenarios where security, data resilience, and disaster recovery are important concerns.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_multi_tenancy_with_data_science_pipeline_applications"><a class="anchor" href="#_multi_tenancy_with_data_science_pipeline_applications"></a>Multi-Tenancy with Data Science Pipeline Applications</h2>
<div class="sectionbody">
<div class="paragraph">
<p>As previously mentioned, Data Science Pipelines is designed to be a secure multi-tenant solution.  This means that multiple users and teams can all securely use their own instances of Data Science Pipelines without fear of leaking data from the pipelines to other users or groups.</p>
</div>
<div class="paragraph">
<p>This multi-tenancy capability does require that each user or group needs their own instance of the <strong>DataSciencePipelineApplication</strong> instance.  Additionally, it is strongly recommended that each <strong>DataSciencePipelineApplication</strong> instance should have its own S3 instance that does not allow other groups to access.</p>
</div>
<div class="paragraph">
<p>While a <strong>DataSciencePipelineApplication</strong> is a namespace scoped object, workbenches and pods running in other namespaces can still interact with the pipeline instance if they have the correct permissions.</p>
</div>
<div class="paragraph">
<p>Only one dpsa deployment can exist per data science project. (nampespace)</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_exercise_create_a_data_science_pipeline_instance"><a class="anchor" href="#_exercise_create_a_data_science_pipeline_instance"></a>Exercise: Create a Data Science Pipeline Instance</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To begin we will use the <strong>Minio</strong> instance created with the lab environment to act as the S3 artifact storage for the <strong>DataSciencePipelineApplication</strong>.</p>
</div>
<div class="sect2">
<h3 id="_create_a_data_science_pipeline_application"><a class="anchor" href="#_create_a_data_science_pipeline_application"></a>Create a Data Science Pipeline Application</h3>
<div class="paragraph">
<p>Next we will create a data connection for the Minio instance, and use that data connection to create a <strong>DataSciencePipelineApplication</strong>.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/data_connection_setup.gif" alt="data connection setup" width="600">
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>From the OpenShift AI Dashboard, navigate to the <code>fraud-detection</code> project we previously created.  Click on the option to <code>Add data connection</code>.</p>
</li>
<li>
<p>Enter the following details and click <code>Add data connections</code>:</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Name: pipelines
Access key: minio
Secret key: minio321!
Endpoint: http://minio-service.pipelines-example.svc:9000
Bucket: pipelines</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Name: storage
Access key: minio
Secret key: minio321!
Endpoint: http://minio-service.pipelines-example.svc:9000
Bucket: storage</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>At this point in time, if the minio instance did not contain a bucket called <code>pipelines</code>.  Once the <strong>DataSciencePipelineApplication</strong> object is created, it will automatically create the bucket for us if it doesn&#8217;t exist.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>A <code>Data Connection</code> is simply a standard kubernetes secret object that contains the fields required to connect to an S3 compatible solution.  This secret can be managed via GitOps just like any other standard kubernetes secret object.  However, not all fields in the Data Connection are dynamically consumed by the <strong>DataSciencePipelineApplication</strong> object, so be careful when updating the endpoint url or the bucket values.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/pipeline_server_setup.gif" alt="pipeline server setup" width="600">
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>A new Data connection should now be listed in the <code>Data connections</code> section.</p>
</li>
<li>
<p>Click on the <code>Configure pipeline server</code> in the <code>Pipelines</code> section of the Data Science Project view.</p>
</li>
<li>
<p>Click the key icon in the right side of the <code>Access Key</code> field, and select the <code>data-science-pipelines</code> data connection. The fields in the form are automatically populated.</p>
</li>
<li>
<p>Click <code>Configure pipeline server</code>. After several seconds, the loading icon should complete and the <code>Pipelines</code> section will now show an option to <code>Import pipeline</code> along with a message that says <code>No pipelines</code>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The <strong>DataSciencePipelineApplication</strong> has now successfully been configured and is ready for use.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_managing_permissions_to_the_datasciencepipelineapplication"><a class="anchor" href="#_managing_permissions_to_the_datasciencepipelineapplication"></a>Managing Permissions to the DataSciencePipelineApplication</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The <strong>DataSciencePipelineApplication</strong> API endpoint route is protected using an OpenShift OAuth Proxy sidecar.</p>
</div>
<div class="paragraph">
<p>The OAuth Proxy requires anything attempting to access the endpoint to be authenticated using the built in OpenShift login.  OpenShift is then able to admit or reject requests to the endpoint based on the Role Based Access and Control configuration of the resources in the namespace.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>To Learn more about the OpenShift OAuth Proxy, please refer to the official git repo:</p>
</div>
<div class="paragraph">
<p><a href="https://github.com/openshift/oauth-proxy" class="bare" target="_blank" rel="noopener">https://github.com/openshift/oauth-proxy</a></p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In particular, the <strong>DataSciencePipelineApplication</strong> requires that users or Service Accounts have <code>get</code> access to the <strong>DataSciencePipelineApplication</strong> route object.</p>
</div>
<div class="paragraph">
<p>Any user that has already been granted <code>Admin</code> or <code>Edit</code> access to the namespace in which the <strong>DataSciencePipelineApplication</strong> is installed will have permission to access the object.</p>
</div>
<div class="paragraph">
<p>It may be necessary to grant access to other resources such as a Service Account in the cluster to be able to interact with the API endpoint.</p>
</div>
<div class="paragraph">
<p>To grant access to an object such as a Service Account, you must first create a role in the namespace (project) where the <strong>DataSciencePipelineApplication</strong> is located that grants <code>get</code> access to the route object:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: dspa-access
  namespace: my-project
rules:
  - verbs:
      - get
    apiGroups:
      - route.openshift.io
    resources:
      - routes</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once the role has been created, a <code>RoleBinding</code> can grant the appropriate permissions to the user or Service Account:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: dspa-access-my-service-account
  namespace: my-project
subjects:
  - kind: ServiceAccount
    name: my-service-account
    namespace: my-project
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: dspa-access</code></pre>
</div>
</div>
<div class="paragraph">
<p>When programmatically accessing the API endpoint, a user can authenticate to the endpoint by passing the <code>BearerToken</code> header value in the http request.  Users can obtain their bearer token from the <code>Copy Login Command</code> menu option in the OpenShift Web Console, or by running the following command once they are already logged in:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">$ oc whoami --show-token</code></pre>
</div>
</div>
<div class="paragraph">
<p>Using the bearer token to authenticate to the endpoint will be discussed in more detail in the section discussing the <code>Kubeflow Pipelines SDK</code>.</p>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="managing-dsp-pipelines.html">RHOAI Pipeline Overview</a></span>
  <span class="next"><a href="rhoai-resources.html">OpenShift AI Resources</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
