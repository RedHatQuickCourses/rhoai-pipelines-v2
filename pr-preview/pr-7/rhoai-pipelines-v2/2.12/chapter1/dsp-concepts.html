<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Data Science Pipeline Concepts :: RHOAI Data Science Pipelines</title>
    <link rel="prev" href="dsp-intro.html">
    <link rel="next" href="../chapter2/index.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">RHOAI Data Science Pipelines</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="rhoai-pipelines-v2" data-version="2.12">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">RHOAI Data Science Pipelines</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../LABENV/index.html">Lab Environment</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/minio-install.html">MinIO S3 Compatible Storage Setup</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="dsp-intro.html">Introduction to ML Pipelines</a>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="dsp-concepts.html">Data Science Pipeline Concepts</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter2/index.html">Data Science Pipelines</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/managing-dsp-pipelines.html">RHOAI Pipeline Overview</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/data-science-pipeline-app.html">Data Science Pipeline Applications</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/rhoai-resources.html">OpenShift AI Resources</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter3/index.html">Creating Pipelines with Elyra</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter3/elyra-pipelines.html">Elyra Pipelines</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter4/index.html">KFP SDK</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter4/section1.html">blah blah blah 2</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter4/section2.html">Importing Pipelines</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../appendix/appendix.html">Appendix A</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">RHOAI Data Science Pipelines</span>
    <span class="version">2.12</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">RHOAI Data Science Pipelines</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">2.12</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">RHOAI Data Science Pipelines</a></li>
    <li><a href="dsp-intro.html">Introduction to ML Pipelines</a></li>
    <li><a href="dsp-concepts.html">Data Science Pipeline Concepts</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Data Science Pipeline Concepts</h1>
<div id="preamble">
<div class="sectionbody">
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>A pipeline is an execution graph of tasks, commonly known as a <em>DAG</em> (Directed Acyclic Graph).
A DAG is a directed graph without any cycles, i.e. direct loops.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/pipeline_dag_overview.gif" alt="pipeline dag overview" width="600">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_specific_data_science_pipeline_terminology_in_openshift_ai_dsp"><a class="anchor" href="#_specific_data_science_pipeline_terminology_in_openshift_ai_dsp"></a>Specific Data Science Pipeline terminology in OpenShift AI DSP</h2>
<div class="sectionbody">
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Pipeline</strong> - is a workflow definition containing the steps and their input and output artifacts.</p>
</li>
<li>
<p><strong>Run</strong> - is a single execution of a pipeline. A run can be a one off execution of a pipeline, or pipelines can be scheduled as a recurring run.</p>
</li>
<li>
<p><strong>Task</strong> - is a self-contained pipeline component that represents an execution stage in the pipeline.</p>
</li>
<li>
<p><strong>Artifact</strong> - Steps have the ability to create artifacts, which are objects that can be persisted after the execution of the step completes. Other steps may use those artifacts as inputs and some artifacts may be useful references after a pipeline run has completed. Artifacts automatically stored by Data Science Pipelines in S3 compatible storage.</p>
</li>
<li>
<p><strong>Experiment</strong> - is a logical grouping of runs for the purpose of comparing different pipelines</p>
</li>
<li>
<p><strong>Execution</strong> -  is an instance of a Task/Component</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_why_data_science_pipelines"><a class="anchor" href="#_why_data_science_pipelines"></a>Why data science pipelines</h2>
<div class="sectionbody">
<div class="paragraph">
<p>A data science pipeline is typically implemented to improve the repeatability of a data science experiment.  While the larger experimentation process may include steps such as data exploration, where data scientists seek to create a fundamental understanding of the characteristics of the data, data science pipelines tend to focus on turning a viable experiment into a repeatable solution that can be iterated on.</p>
</div>
<div class="paragraph">
<p>A data science pipeline, may also fit within the context of a larger pipeline that manages the complete lifecycle of an application, and the data science pipeline is responsible for the process of training the machine learning model.</p>
</div>
<div class="paragraph">
<p>Data science pipelines may consists of several key activities that are performed in a structured sequence to train a machine learning model. These activities may include:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Data Collection</strong>: Gathering the data from various sources, such as databases, APIs, spreadsheets, or external datasets.</p>
</li>
<li>
<p><strong>Data Cleaning</strong>: Identifying and handling missing or inconsistent data, removing duplicates, and addressing data quality issues to ensure that the data is reliable and ready for analysis.</p>
</li>
<li>
<p><strong>Feature Engineering</strong>: Creating or transforming features (variables) to improve the performance of machine learning models. This may involve scaling, one-hot encoding, creating new variables, or reducing dimensionality.</p>
</li>
<li>
<p><strong>Data Preprocessing</strong>: Preparing the data for modeling, which may involve standardizing, normalizing, or scaling the data. This step is crucial for machine learning algorithms that are sensitive to the scale of features.  This step may also include splitting the data into multiple subsets of data including a test and train dataset to allow the model to be validated using data the trained model has never seen.</p>
</li>
<li>
<p><strong>Model Training</strong>: After the data has been split into an appropriate subset, the model is trained using the training dataset.  As part of the training process, the machine learning algorithm will generally iterate through the training data, making adjustments to the model until it arrives at the "best" version of the model.</p>
</li>
<li>
<p><strong>Model Evaluation</strong>: The model performance is assessed with the previously unseen test dataset using various metrics, such as accuracy, precision, recall, F1 score, or mean squared error. Cross-validation techniques may be used to ensure the model&#8217;s robustness.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>A single pipeline may include the ability to train multiple models, complete complex hyperparameter searches, or more.  Data Scientists can use a well crafted pipeline to quickly iterate on a model, adjust how data is transformed, test different algorithms, and more.  While the steps described above describe a common pattern for model training, different use cases and projects may have vastly different requirements and the tools and framework selected for creating a data science pipeline should help to enable a flexible design.</p>
</div>
<div class="sect2">
<h3 id="_technical_knowledge"><a class="anchor" href="#_technical_knowledge"></a>Technical Knowledge</h3>
<div class="paragraph">
<p>OpenShift AI uses Kubeflow pipelines with Argo workflows as the engine. Kubeflow provides a rich set of tools for managing ML workloads, while Argo workflows offer powerful automation capabilities. Together, they enable us to create robust, scalable, and manageable pipelines for AI model development and serving.</p>
</div>
<div class="paragraph">
<p>Pipelines can include various components, such as data ingestion, data preprocessing, model training, evaluation, and deployment. These components can be configured to run in a specific order, and the pipeline can be executed multiple times to produce different versions of models or artifacts.</p>
</div>
<div class="paragraph">
<p>Additionally, pipelines can support control flows to handle complex dependencies between tasks. Once a pipeline is defined, executing it becomes a simple RUN command, and the status of each execution can be tracked and monitored, ensuring that the desired outputs are produced successfully.</p>
</div>
<div class="paragraph">
<p>In summary, data science pipelines are an essential tool for automating and managing the ML lifecycle, enabling data scientists to create end-to-end workflows, reduce human error, and ensure consistent, high-quality results.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s explore how to build and deploy these powerful pipelines using OpenShift AI data science pipelines.</p>
</div>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="dsp-intro.html">Introduction to ML Pipelines</a></span>
  <span class="next"><a href="../chapter2/index.html">Data Science Pipelines</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
