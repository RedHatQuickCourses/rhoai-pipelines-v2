= OpenShift AI Resources

== Data connection

 
The next step is to create a *Data Connection* in our Data Science Project.  Before we can create our Data Connection, we will setup MinIO as our S3 compatible storage for this Lab. 

Continue to the next section to deploy and configure Minio. 

== Create Data Connection 

Navigate to the Data Science Project section of the OpenShift AI Console /Dashboard. Select the Ollama-model project. 

. Select the Data Connection menu, followed by create data connection
. Provide the following values:
..  Name:  *models*
..  Access Key: use the minio_root-user from YAML file
..  Secret Key: use the minio_root_password from the YAML File
..  Endpoint: use the Minio API URL from the Routes page in Openshift Dashboard
..  Region: This is required for AWS storage & cannot be blank (no-region-minio)
.. Bucket: use the Minio Storage bucket name: *models* 

//image::dataconnection_models.png[width=800]

Repeat the same process for the Storage bucket, using *storage* for the name & bucket.

== Creating a WorkBench 

//video::openshiftai_setup_part3.mp4[width=640]

Navigate to the Data Science Project section of the OpenShift AI Console /Dashboard. Select the Ollama-model project.  

//image::create_workbench.png[width=640]

 . Select the WorkBench button, then click create workbench

 .. Name:  `tbd`

 .. Notebook Image:  `Minimal Python`

 .. Leave the remaining options default.

 .. Optionally, scroll to the bottom, check the `Use data connection box`.
 
 .. Select *storage* from the dropdown to attach the storage bucket to the workbench.  

 . Select the Create Workbench option.

[NOTE]
Depending on the notebook image selected, it can take between 2-20 minutes for the container image to be fully deployed. The Open Link will be available when our container is fully deployed.  



== Jupyter Notebooks

// video::llm_jupyter_v3.mp4[width=640]

== Open JupyterLab 

JupyterLab enables you to work with documents and activities such as Jupyter notebooks, text editors, terminals, and custom components in a flexible, integrated, and extensible manner. For a demonstration of JupyterLab and its features, https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html#what-will-happen-to-the-classic-notebook[you can view this video.]


Return to the ollama-model workbench dashboard in the OpenShift AI console.

 . Select the *Open* link to the right of the status section.
+
image::oai_open_jupyter.png[width=640]

 . When the new window opens, use the OpenShift admin user & password to login to JupyterLab. 

 . Click the *Allow selected permissions* button to complete login to the notebook.


[NOTE]
If the *OPEN* link for the notebook is grayed out, the notebook container is still starting. This process can take a few minutes & up to 20+ minutes depending on the notebook image we opted to choose.


== Inside JupyterLab

This takes us to the JupyterLab screen where we can select multiple options / tools / to work to begin our data science experimentation.

Our first action is to clone a git repository that contains a collection of LLM projects including  the notebook we are going to use to interact with the LLM. 

Clone the github repository to interact with the Ollama Framework from this location:
https://github.com/rh-aiservices-bu/llm-on-openshift.git

 . Copy the URL link above

 . Click on the Clone a Repo Icon above explorer section window.
+
image::clone_a_repo.png[width=640]

 . Paste the link into the *clone a repo* pop up,   make sure the *included submodules are checked*, then click the clone.
 
 . Navigate to the llm-on-openshift/examples/notebooks/langchain folder:

 . Then open the file: _Langchain-Ollama-Prompt-memory.ipynb_
+
image::navigate_ollama_notebook.png[width=640]

 . Explore the notebook, and then continue.
