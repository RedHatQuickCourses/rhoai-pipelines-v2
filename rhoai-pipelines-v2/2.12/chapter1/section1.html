<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>RHOAI DSP specifics :: RHOAI Data Science Pipelines</title>
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">RHOAI Data Science Pipelines</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="rhoai-pipelines-v2" data-version="2.12">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">RHOAI Data Science Pipelines</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../LABENV/index.html">Lab Environment</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../LABENV/minio-install.html">MinIO S3 Compatible Storage Setup</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="dsp-intro.html">Introduction to ML Pipelines</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="dsp-concepts.html">Data Science Pipeline Concepts</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter2/index.html">Data Science Pipelines</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/data-science-pipeline-app.html">Data Science Pipeline Applications</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/rhoai-resources.html">OpenShift AI Resources</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter3/index.html">Creating Pipelines with Elyra</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter3/elyra-pipelines.html">Elyra Pipelines</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter4/index.html">KFP SDK</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter4/kfp-import.html">Kubeflow Pipelines SDK</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../appendix/appendix.html">Appendix A</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">RHOAI Data Science Pipelines</span>
    <span class="version">2.12</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">RHOAI Data Science Pipelines</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">2.12</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">RHOAI Data Science Pipelines</a></li>
    <li><a href="section1.html">RHOAI DSP specifics</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">RHOAI DSP specifics</h1>
<div class="sect1">
<h2 id="_specific_data_science_pipeline_terminology_in_openshift_ai_dsp"><a class="anchor" href="#_specific_data_science_pipeline_terminology_in_openshift_ai_dsp"></a>Specific Data Science Pipeline terminology in OpenShift AI DSP</h2>
<div class="sectionbody">
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Pipeline</strong> - is a workflow definition containing the steps and their input and output artifacts.</p>
</li>
<li>
<p><strong>Run</strong> - is a single execution of a pipeline. A run can be a one off execution of a pipeline, or pipelines can be scheduled as a recurring run.</p>
</li>
<li>
<p><strong>Task</strong> - is a self-contained pipeline component that represents an execution stage in the pipeline.</p>
</li>
<li>
<p><strong>Artifact</strong> - Steps have the ability to create artifacts, which are objects that can be persisted after the execution of the step completes. Other steps may use those artifacts as inputs and some artifacts may be useful references after a pipeline run has completed. Artifacts automatically stored by Data Science Pipelines in S3 compatible storage.</p>
</li>
<li>
<p><strong>Experiment</strong> - is a logical grouping of runs for the purpose of comparing different pipelines</p>
</li>
<li>
<p><strong>Execution</strong> -  is an instance of a Task/Component</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_managing_data_science_pipelines_2_0"><a class="anchor" href="#_managing_data_science_pipelines_2_0"></a>Managing Data Science Pipelines 2.0</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_configuring_a_pipeline_server"><a class="anchor" href="#_configuring_a_pipeline_server"></a>Configuring a pipeline server</h3>
<div class="paragraph">
<p>Before you can successfully create a pipeline in OpenShift AI, you must configure a pipeline server. This task includes configuring where your pipeline artifacts and data are stored.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>You have an existing S3-compatible object storage bucket and you have configured write access to your S3 bucket on your storage account.</p>
</li>
<li>
<p>You have created a data science project that you can add a pipeline server to.</p>
</li>
<li>
<p>If you are configuring a pipeline server with an external database</p>
<div class="ulist">
<ul>
<li>
<p>Red Hat recommends that you use MySQL version 8.x.</p>
</li>
<li>
<p>Red Hat recommends that you use at least MariaDB version 10.5.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_defining_a_pipeline_2_0"><a class="anchor" href="#_defining_a_pipeline_2_0"></a>Defining a  Pipeline 2.0</h3>
<div class="paragraph">
<p>Use the latest Kubeflow Pipelines 2.0 SDK to build your data science pipeline in Python code. After you have built your pipeline, use the SDK to compile it into an Intermediate Representation (IR) YAML file. After defining the pipeline, you can import the YAML file to the OpenShift AI dashboard to enable you to configure its execution settings.</p>
</div>
<div class="paragraph">
<p>You can also use the Elyra JupyterLab extension to create and run data science pipelines within JupyterLab. For more information about creating pipelines in JupyterLab, see Creating Pipelines in Elyra in the section below. For more information about the Elyra JupyterLab extension, <a href="https://elyra.readthedocs.io/en/v2.0.0/getting_started/overview.html">see Elyra Documentation.</a></p>
</div>
</div>
<div class="sect2">
<h3 id="_importing_a_pipeline_2_0"><a class="anchor" href="#_importing_a_pipeline_2_0"></a>Importing a  Pipeline 2.0</h3>
<div class="paragraph">
<p>To help you begin working with data science pipelines in OpenShift AI, you can import a YAML file containing your pipelineâ€™s code to an active pipeline server, or you can import the YAML file from a URL.
This file contains a Kubeflow pipeline compiled by using the Kubeflow compiler. After you have imported the pipeline to a pipeline server, you can execute the pipeline by creating a pipeline run.</p>
</div>
</div>
<div class="sect2">
<h3 id="_pipeline_actions"><a class="anchor" href="#_pipeline_actions"></a>Pipeline Actions</h3>
<div class="paragraph">
<p>OpenShift AI data science pipelines supports the following actions:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Creating</p>
</li>
<li>
<p>Scheduling</p>
</li>
<li>
<p>Executing</p>
</li>
<li>
<p>Viewing</p>
</li>
<li>
<p>Archiving</p>
</li>
<li>
<p>Restoring</p>
</li>
<li>
<p>Deleting</p>
</li>
<li>
<p>Stopping</p>
</li>
<li>
<p>Duplicating</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_working_with_pipeline_logs"><a class="anchor" href="#_working_with_pipeline_logs"></a>Working with pipeline logs</h3>
<div class="paragraph">
<p>You can review and analyze step logs for each step in a triggered pipeline run.
To help you troubleshoot and audit your pipelines, you can review and analyze these step logs by using the log viewer in the OpenShift AI dashboard.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Viewing logs</p>
</li>
<li>
<p>Downloading logs</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_technical_knowledge"><a class="anchor" href="#_technical_knowledge"></a>Technical Knowledge</h3>
<div class="paragraph">
<p>OpenShift AI uses Kubeflow pipelines with Argo workflows as the engine. Kubeflow provides a rich set of tools for managing ML workloads, while Argo workflows offer powerful automation capabilities. Together, they enable us to create robust, scalable, and manageable pipelines for AI model development and serving.</p>
</div>
<div class="paragraph">
<p>Pipelines can include various components, such as data ingestion, data preprocessing, model training, evaluation, and deployment. These components can be configured to run in a specific order, and the pipeline can be executed multiple times to produce different versions of models or artifacts.</p>
</div>
<div class="paragraph">
<p>Additionally, pipelines can support control flows to handle complex dependencies between tasks. Once a pipeline is defined, executing it becomes a simple RUN command, and the status of each execution can be tracked and monitored, ensuring that the desired outputs are produced successfully.</p>
</div>
<div class="paragraph">
<p>In summary, data science pipelines are an essential tool for automating and managing the ML lifecycle, enabling data scientists to create end-to-end workflows, reduce human error, and ensure consistent, high-quality results.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s explore how to build and deploy these powerful pipelines using OpenShift AI data science pipelines.</p>
</div>
</div>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
